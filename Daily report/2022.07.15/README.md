### (2022년 7월 15일) 도로 환경을 바꾸고 학습이 이루어지지 않는다..
도로 환경이 간단해지면 간단해졌지 좁아지거나 어려운 커브길이 생긴것이 아니다.
하이퍼 파라미터 설계, 에이전트에 주어지는 보상 설계를 다시 해봐야겠다.

1. 이동한 거리에 비례하여 보상 부여: 단위 step 당 속도에 따라 이동한 거리에 보상을 부여하여 결과적으로 빠른 속도로 주행할 수 있도록 한다.

2. 벽(연석)에 부딪힐 경우 큰 (-) 보상 부여: 기존에 설계한 보상에서 벽에 부딪힐 경우 훨씬 큰 (-) 보상을 부여하여 벽에 박으면 큰일이 난다는 것을 인식할 수 있도록 한다.

3. 목표지점에 도착할 경우 큰 (+) 보상 부여: 벽에 부딪혔을 때와 비슷하게 큰 보상을 줌으로서 다시 목표지점에 도달할 수 있도록 한다.

4. 중앙선 넘어서 주행할 경우 복구 못할 정도의 (-) 보상 부여: 벽에 부딪혔을 때 만큼은 아니지만 큰 (-) 보상을 부여하여 다시 정상 주행을 해도 복구 못하도록 한다.

5. Epsilon greedy의 Epsilon-decay 키우기: 기존의 Epsilon greedy 방식에서는 Epsilon이 1에서 0.00001씩 선형적으로 감소하게 설계되어 있었다. 이에 평균적으로 4000 에피소드가 지남에도 랜덤한 행동 선택을 많이 할 것 같아 epsilon decay 크기를 키워 어느정도 에피소드가 지나면 maxQ 값에 따른 행동 선택을 하게끔 한다.

6. Target network update 작게: Target network update 횟수가 기존에는 너무 적어 학습이 제대로 이루어지지 않은 것이라 판단하여 작게한다.